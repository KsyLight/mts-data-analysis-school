{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29cf9c86-29d8-42ce-8663-0ef443924c0a",
   "metadata": {},
   "source": [
    "# Домашнее задание NN 3 | Василенко Егор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866597b5-1c1c-40a2-b672-096ffbb09930",
   "metadata": {},
   "source": [
    "## Введение (Intro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e33ac-37e0-49ea-9d44-926342ec9c35",
   "metadata": {},
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f326b2-4725-4b91-8a9d-48a46e3c5eaa",
   "metadata": {},
   "source": [
    "Реализовать полный RAG-пайплайн, используя фреймворк LangChain. В качестве источника знаний выберите один из двух вариантов:\n",
    "\n",
    "1. Книга: Любая книга в электронном формате (PDF, TXT, ePub). Это может быть техническая документация, художественное произведение или научная работа.\n",
    "2. Кодовая база: Исходный код небольшого или среднего проекта. Идеальный вариант - склонировать публичный Git-репозиторий.\n",
    "\n",
    "После создания RAG-системы вам нужно продемонстрировать её работу на трёх тщательно подобранных (\"cherry-picked\") примерах запросов, которые показывают сильные и, возможно, слабые стороны вашего решения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6680fff9-0ecb-4c61-9532-42b95bb34271",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bb7fd0-af1c-4da8-b037-100bb03c2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут много пометок для себя — надеюсь, не будут лишними\n",
    "# Работа с файловой системой и утилиты\n",
    "from pathlib import Path\n",
    "import os\n",
    "import textwrap # Форматирование текста\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Загрузка и обработка документов (LangChain)\n",
    "from langchain_community.document_loaders import PyMuPDFLoader # Загрузка PDF через PyMuPDF\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # Разбиение текста на чанки\n",
    "\n",
    "# Векторизация и поиск (LangChain + HuggingFace)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings # Эмбеддинги через HuggingFace\n",
    "from langchain_community.vectorstores import Chroma # Векторное хранилище Chroma\n",
    "from langchain_community.retrievers import BM25Retriever # Текстовый поиск BM25\n",
    "from langchain.retrievers import EnsembleRetriever # Ансамблевый ретривер\n",
    "\n",
    "# LLM и генерация ответов (Ollama)\n",
    "from langchain_ollama import OllamaLLM # LLM через Ollama\n",
    "from langchain.prompts import PromptTemplate # Шаблоны подсказок\n",
    "from langchain.chains import RetrievalQA # Цепочка вопрос-ответ с ретривером"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f4da7-be7c-4495-89f0-553316560c03",
   "metadata": {},
   "source": [
    "## RAG-система"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa442a-9677-49ae-8a44-a7a641822b27",
   "metadata": {},
   "source": [
    "### Конфиг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e3113b-061e-43f6-bf63-5587dc954375",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"prestuplenie_i_nakazanie.pdf\"\n",
    "PERSIST_DIR = \"chroma_db\"\n",
    "COLLECTION = \"book_ru\"\n",
    "\n",
    "# Разбиение\n",
    "CHUNK_SIZE = 800\n",
    "CHUNK_OVERLAP = 160\n",
    "\n",
    "# Эмбеддинги (многоязычные, нормализация обязательна)\n",
    "EMB_MODEL = \"intfloat/multilingual-e5-base\"\n",
    "\n",
    "# Модель LLM в Ollama\n",
    "OLLAMA_MODEL = \"mistral:7b-instruct-q4_K_M\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a0526-24c2-4d8f-95fa-8617352b1efb",
   "metadata": {},
   "source": [
    "### Загрузка и предварительная чистка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d725fce-0b44-4114-9efc-9e634cb6f7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Страниц загружено: 316\n"
     ]
    }
   ],
   "source": [
    "# PyMuPDFLoader обычно чище вытаскивает русский текст из PDF\n",
    "loader = PyMuPDFLoader(PDF_PATH)\n",
    "docs = loader.load()\n",
    "print(f\"Страниц загружено: {len(docs)}\")\n",
    "\n",
    "# Мини-чистка: склейка переносов, убираем лишние пробелы\n",
    "for d in docs:\n",
    "    t = d.page_content\n",
    "    t = t.replace(\"-\\n\", \"\") # Переносы со знаком \"-\"\n",
    "    t = t.replace(\"\\n\", \" \") # Переводы строк -> пробел\n",
    "    d.page_content = \" \".join(t.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e89ca8-5560-4f99-8f1c-55e6c930c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чанков получено: 1818\n"
     ]
    }
   ],
   "source": [
    "# Сплиттер на чанки\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    ")\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(f\"Чанков получено: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb7a30e-16cf-4d3b-a0e0-2265b9694245",
   "metadata": {},
   "source": [
    "### Эмбеддинги и персистентная Chroma (с поддержкой повторного запуска)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e36905-97f2-4c25-8942-5a929aab3fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_31448\\3698802203.py:19: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс открыт из персистентного хранилища.\n"
     ]
    }
   ],
   "source": [
    "# Определяем устройство для эмбеддингов\n",
    "try:\n",
    "    import torch\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "except Exception:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMB_MODEL,\n",
    "    model_kwargs={\"device\": DEVICE},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")\n",
    "\n",
    "persist_path = Path(PERSIST_DIR)\n",
    "\n",
    "if persist_path.exists():\n",
    "    # Повторный запуск — просто открываем уже созданную коллекцию\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=PERSIST_DIR,\n",
    "        collection_name=COLLECTION,\n",
    "        embedding_function=embeddings,\n",
    "    )\n",
    "    print(\"Индекс открыт из персистентного хранилища.\")\n",
    "else:\n",
    "    # Первый запуск — создаём коллекцию из документов и сохраняем\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=PERSIST_DIR,\n",
    "        collection_name=COLLECTION,\n",
    "    )\n",
    "    vectorstore.persist()\n",
    "    print(\"Индекс создан и сохранён.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fef897-2129-434a-90b2-a6ca7bb1ee94",
   "metadata": {},
   "source": [
    "### Гибридный ретривер (BM25 + векторный MMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98f06d7f-191b-42a7-944e-bdf19c6fd474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 хорошо ловит точные слова/имена, MMR — разнообразие и смысл\n",
    "bm25 = BM25Retriever.from_documents(chunks)\n",
    "bm25.k = 8\n",
    "\n",
    "vec = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 6, \"lambda_mult\": 0.5} # Компактнее, меньше шума\n",
    ")\n",
    "\n",
    "# Смешиваем веса 0.5/0.5 — честный компромисс; поднимал вес BM25 до 0.7, но на опыте это ничего не дало\n",
    "retriever = EnsembleRetriever(retrievers=[vec, bm25], weights=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "009a8b23-889e-4364-bbe1-a096f5c7335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Утилита для быстрой подстройки k\n",
    "def set_k(vec_k: int = 6, bm25_k: int = 8):\n",
    "    vec.search_kwargs[\"k\"] = vec_k\n",
    "    bm25.k = bm25_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0caf0fe0-c794-4b24-9d66-eb5835966737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM через Ollama\n",
    "llm = OllamaLLM(\n",
    "    model=OLLAMA_MODEL,\n",
    "    temperature=0.15,\n",
    "    top_p=0.9,\n",
    "    repeat_penalty=1.1,\n",
    "    num_ctx=4096,\n",
    "    num_predict=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc31f9-3578-4493-822d-a04700fe5015",
   "metadata": {},
   "source": [
    "### Строгий системный промпт и сборка RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58a006cd-6fa2-4427-a163-9e2821abcf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT_RAG = \"\"\"\n",
    "Ты отвечаешь строго ТОЛЬКО по приведённому ниже КОНТЕКСТУ.\n",
    "Если нужной информации нет — ответь: \"В предоставленном контексте информации нет.\"\n",
    "Не цитируй длинные куски и не пересказывай контекст.\n",
    "Пиши на русском. Для факт-вопросов отвечай кратко: одно имя/словосочетание (1–5 слов), без пояснений.\n",
    "\n",
    "КОНТЕКСТ:\n",
    "{context}\n",
    "\n",
    "ВОПРОС:\n",
    "{question}\n",
    "\n",
    "Ответ:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b457772f-4537-4f4a-9b8c-e90a67974878",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=SYS_PROMPT_RAG,\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99a42556-99ea-483c-8b47-8249d33cb15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a51fe9-e82f-4ba4-9a2b-dea3b7f7260c",
   "metadata": {},
   "source": [
    "### Демонстрация: 3 запроса (факт/синтез/сложный)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35ec41d5-270a-443c-9919-70041469ffc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ФАКТ =====\n",
      "Вопрос: Как зовут сестру Раскольникова?\n",
      "Ответ : \n",
      "В предоставленном контексте информации нет.\n",
      "Контекст:\n",
      "  – стр.?: . Другого платья у него не было, а если б и было, он, быть может, и не надел бы его, — «так, нарочно бы не…\n",
      "  – стр.?: !» Катерина Ивановна с презрением заметила, что ее происхождение всем известно и что в этом самом похвальном…\n",
      "  – стр.?: таясь, открываются оба глаза: они обводят его огненным и бесстыдным взглядом, они зовут его, смеются… Что-то…\n",
      "  – стр.?: . — А молиться вы умеете? — О, как же, умеем! Давно уже; я, как уж большая, то молюсь сама про себя, а Коля с…\n",
      "  – стр.?: . Они стали говорить о Лизавете. Студент рассказывал о ней с каким-то особенным удовольствием и все смеялся,…\n",
      "  – стр.?: . Оба с минуту смотрели друг на друга и ждали. Принесли воды. — Это я … — начал было Раскольников. — Выпейте…\n",
      "  – стр.?: . Это ты покамест, значит, не хочешь теперь и гораздо важнейшими делами занимаешься… — Дуни дома нет, мамаша?…\n",
      "  – стр.?: . Но его ни с вами, ни кругом вас не было, я — таки смотрел: это отважно, хотели, значит, пощадить Родиона…\n",
      "\n",
      "===== СИНТЕЗ =====\n",
      "Вопрос: Как изменяется отношение Раскольникова к Сонечке Мармеладовой на протяжении романа? Опиши этапы.\n",
      "Ответ : \n",
      "В предоставленном контексте информации нет.\n",
      "Контекст:\n",
      "  – стр.?: Петр Петрович искоса посмотрел на Раскольникова. Взгляды их встретились. Горящий взгляд Раскольникова готов…\n",
      "  – стр.?: . Человек остановился на пороге, посмотрел молча на Раскольникова и ступил шаг в комнату. Он был точь-в-точь…\n",
      "  – стр.?: . — Как же, имел удовольствие… вчера, — пробормотал Лужин, неприязненно покосившись на Разумихина, затем…\n",
      "  – стр.?: . «А черт возьми это все! — подумал он вдруг в припадке неистощимой злобы. — Ну началось, так и началось,…\n",
      "  – стр.?: . Разумихин откланялся и весь засиял. На одно мгновение все как-то странно вдруг законфузились. — Прощай,…\n",
      "  – стр.?: . Вдруг в сердце своем он ощутил почти радость: ему захотелось поскорее к Катерине Ивановне. На похороны он,…\n",
      "  – стр.?: Бывают иные встречи, совершенно даже с незнакомыми нам людьми, которыми мы начинаем интересоваться с первого…\n",
      "  – стр.?: . Еще в начале процесса мать Раскольникова сделалась больна. Дуня и Разумихин нашли возможным увезти ее из…\n",
      "\n",
      "===== СЛОЖНЫЙ =====\n",
      "Вопрос: Каким образом в книге упоминается персонаж Гарри Поттер?\n",
      "Ответ : \n",
      "В предоставленном контексте информации нет.\n",
      "Контекст:\n",
      "  – стр.?: . Каким же образом мог я ей передать, после этого? — Я видел, видел! — кричал и подтверждал Лебезятников, — и…\n",
      "  – стр.?: . Да сядьте же! — Каким образом вы можете его спасти? Разве его можно спасти? Дуня села. Свидригайлов сел…\n",
      "  – стр.?: . Пустите меня… — Куда вы? Да куда вы? — К нему. Где он? Вы знаете? Отчего эта дверь заперта? Мы сюда вошли в…\n",
      "  – стр.?: . Мало того, всем показывала и читала вслух собственноручное письмо Дунечкино к господину Свидригайлову и…\n",
      "  – стр.?: . Об этом еще не было сообщено Раскольникову самою Катериной Ивановной, и она тотчас же увлеклась в самые…\n",
      "  – стр.?: — Да. Вы слышали? — Как же-с, в соседстве… — В подробности знаете? — Не могу сказать; но меня интересует при…\n",
      "  – стр.?: . Но в комнате не было ничего особенного. Мебель, вся очень старая и из желтого дерева, состояла из дивана с…\n",
      "  – стр.?: . Оба еще были в костюмах: один в чалме, другая в ермолке с страусовым пером. И каким образом этот…\n"
     ]
    }
   ],
   "source": [
    "queries = {\n",
    "    \"Факт\": \"Как зовут сестру Раскольникова?\",\n",
    "    \"Синтез\": \"Как изменяется отношение Раскольникова к Сонечке Мармеладовой на протяжении романа? Опиши этапы.\",\n",
    "    \"Сложный\": \"Каким образом в книге упоминается персонаж Гарри Поттер?\",\n",
    "}\n",
    "\n",
    "for tag, q in queries.items():\n",
    "    print(f\"\\n===== {tag.upper()} =====\")\n",
    "    out = qa_chain.invoke({\"query\": q})\n",
    "    print(\"Вопрос:\", q)\n",
    "    print(\"Ответ :\", out[\"result\"])\n",
    "    print(\"Контекст:\")\n",
    "    for d in out.get(\"source_documents\", []):\n",
    "        short = textwrap.shorten(d.page_content.replace(\"\\n\",\" \"), width=110, placeholder=\"…\")\n",
    "        print(f\"  – стр.{d.metadata.get('page_number', '?')}: {short}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ea803b-6932-414a-8f09-239143f92187",
   "metadata": {},
   "source": [
    "#### Анализ\n",
    "**Факт**\n",
    "- *Контекст:* есть упоминание «Дуни» — это сокращённая форма имени Авдотья, то есть нужный ответ фактически содержится в тексте. Однако модель не распознала, что «Дуня» — это сестра Раскольникова, и не выдала его.  \n",
    "- *Вывод:* ошибка вызвана тем, что поиск выдал релевантный чанк, но синтезатор не связал прозвище с именем. Возможное улучшение — добавить словарь синонимов и уменьшить размер чанков, чтобы уменьшить шум в контексте.\n",
    "\n",
    "**Синтез**\n",
    "- *Контекст:* присутствуют описания взаимодействий между героями, но они разрозненные и не дают целостной картины развития отношения. Модель, вероятно, не смогла синтезировать из этих фрагментов полноценный ответ.  \n",
    "- *Вывод:* ошибка на этапе подбора источников — нужные фрагменты о ключевых этапах отношений не попали в top-k. Для исправления можно увеличить `bm25_k` и добавить более крупные чанк-размеры, чтобы охватить длинные сюжетные линии.\n",
    "\n",
    "**Сложный**\n",
    "- *Контекст:* содержит фразы с «каким образом», но ни одного упоминания Гарри Поттера. Это корректный отказ, так как в произведении персонаж не встречается.  \n",
    "- *Вывод:* модель верно определила отсутствие информации. Здесь улучшений не требуется — поведение соответствует ожидаемому."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a83b0e-a72a-4d66-88c6-89d2365a4048",
   "metadata": {},
   "source": [
    "### Простая авто-оценка фактов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d417d070-b3fa-4809-9f77-a07463a01510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация для честной проверки (ё -> е, регистр, лишние пробелы)\n",
    "def norm(s: str) -> str:\n",
    "    return \" \".join(s.lower().replace(\"ё\", \"е\").split())\n",
    "\n",
    "def evaluate_facts(cases, vec_k: int = 6, bm25_k: int = 8, show_progress: bool = True):\n",
    "    set_k(vec_k=vec_k, bm25_k=bm25_k)\n",
    "    ok, results = 0, []\n",
    "    iterator = tqdm(cases, desc=\"Оценка фактов\", unit=\"вопр.\") if show_progress else cases\n",
    "    total = len(cases)\n",
    "    for i, (q, expected) in enumerate(iterator, 1):\n",
    "        out = qa_chain.invoke({\"query\": q})\n",
    "        ans = norm(out[\"result\"])\n",
    "        ctx = norm(\" \".join(d.page_content for d in out.get(\"source_documents\", [])))\n",
    "        hit = any(norm(e) in ans or norm(e) in ctx for e in expected)\n",
    "        ok += int(hit)\n",
    "        results.append((q, out[\"result\"][:160].replace(\"\\n\",\" \"), hit))\n",
    "        if show_progress:\n",
    "            iterator.set_postfix_str(f\"hit={ok}/{i}\")\n",
    "    acc = ok / total if total else 0.0\n",
    "    return acc, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08420e88-a64b-4b29-8f26-8f814e078c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Небольшой список проверок по роману\n",
    "fact_cases = [\n",
    "    (\"Как зовут сестру Раскольникова?\", [\"Авдотья\", \"Дуня\"]),\n",
    "    (\"Как зовут мать Раскольникова?\", [\"Пульхерия Александровна\"]),\n",
    "    (\"Как зовут следователя, беседующего с Раскольниковым?\", [\"Порфирий Петрович\"]),\n",
    "    (\"Как зовут Сонечку по отчеству?\", [\"Софья Семёновна\", \"Софья Семеновна\"]),\n",
    "    (\"Как зовут помещицу-процентщицу?\", [\"Алёна Ивановна\", \"Алена Ивановна\"]),\n",
    "    (\"Как зовут её сестру?\", [\"Лизавета Ивановна\"]),\n",
    "    (\"Как звали отца Сонечки?\", [\"Семён Захарович\", \"Семен Захарович\", \"Мармеладов\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5543d76-b182-45c8-8c90-d3b32c15482d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Оценка фактов: 100%|█████████████████████████████████████████████████████████| 7/7 [00:34<00:00,  4.95s/вопр., hit=2/7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Точность по фактам: 28.6%\n",
      "[OK] Как зовут сестру Раскольникова? ->  Лизавета\n",
      "[MISS] Как зовут мать Раскольникова? ->  В предоставленном контексте информации нет.\n",
      "[OK] Как зовут следователя, беседующего с Раскольниковым? ->  Неизвестно, потому что в предоставленном контексте информации нет.\n",
      "[MISS] Как зовут Сонечку по отчеству? ->  В предоставленном контексте информации нет.\n",
      "[MISS] Как зовут помещицу-процентщицу? ->  В предоставленном контексте информации нет.\n",
      "[MISS] Как зовут её сестру? ->  В предоставленном контексте информации нет.\n",
      "[MISS] Как звали отца Сонечки? ->  В предоставленном контексте информации нет.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Запуск оценки\n",
    "acc, res = evaluate_facts(fact_cases, vec_k=6, bm25_k=8, show_progress=True)\n",
    "print(f\"\\nТочность по фактам: {acc*100:.1f}%\")\n",
    "for q, ans, hit in res:\n",
    "    print(f\"[{'OK' if hit else 'MISS'}] {q} -> {ans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbff966-c35d-447f-921d-d473585d5237",
   "metadata": {},
   "source": [
    "#### Анализ результата\n",
    "\n",
    "**Общая точность:** 28.6% (2 верных ответа из 7).\n",
    "\n",
    "**Наблюдения:**\n",
    "1. Успехи:  \n",
    "   - Модель верно определила «Лизавета» как сестру Раскольникова.  \n",
    "   - Модель дала ответ «Неизвестно...» для вопроса о следователе, что является корректным отказом при отсутствии информации в контексте.\n",
    "   \n",
    "2. Проблемы:  \n",
    "    - В большинстве случаев модель отвечает «В предоставленном контексте информации нет», даже если фрагменты с нужным ответом встречаются в других чанках. Это говорит о недостаточном покрытии контекстом.\n",
    "    - Есть ошибка в первом успешном примере: «Лизавета» — это на самом деле сестра процентщицы, а не Раскольникова, то есть ответ хоть и из текста, но не тот по смыслу. Это пример галлюцинации из релевантного, но неправильного контекста.\n",
    "   \n",
    "***Вывод:***  \n",
    "- Основная причина низкой точности — непопадание нужных фрагментов в top-k и путаница в идентификации персонажей.\n",
    "- Для улучшения можно:\n",
    "    - увеличить `bm25_k` и `vec_k` (например, 8–10);\n",
    "    - поэкспериментировать с размером чанков;\n",
    "    - добавить словарь синонимов и проверку ответов по сущностям (NER);\n",
    "    - использовать иную модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7da9f0-39e0-47a7-a6ca-a17360a9012d",
   "metadata": {},
   "source": [
    "## Заключение (Outro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fe562f-7e96-4596-a863-066c7dd45dc5",
   "metadata": {},
   "source": [
    "В ходе выполнения работы была реализована система поиска ответов на вопросы по тексту романа с использованием гибридного подхода: векторного поиска (MMR) и лексического поиска (BM25).\n",
    "\n",
    "> Для ускорения работы и оптимизации ресурсов добавил проверку на повторный запуск с использованием персистентного хранилища Chroma.\n",
    "\n",
    "***Проведённая оценка показала точность $28.6%$ по набору тестовых вопросов.***\n",
    "\n",
    "Анализ ошибок выявил следующие основные проблемы:\n",
    "- попадание в контекст релевантных, но не относящихся к вопросу фрагментов, что приводит к неправильным фактам (пример: путаница Лизаветы и сестры Раскольникова);\n",
    "- отсутствие нужной информации в выбранных чанках из-за ограниченного значения `k` и размера чанков;\n",
    "- склонность модели отвечать «В предоставленном контексте информации нет» при частично релевантных данных.\n",
    "\n",
    "**Направления для улучшения:**\n",
    "1. Увеличить значения `bm25_k` и `vec_k` (например, до 8–10) для расширения охвата контекста.\n",
    "2. Подобрать оптимальный размер чанков и степень их перекрытия.\n",
    "3. Добавить предобработку ответов с помощью NER для фильтрации нерелевантных имён.\n",
    "4. Реализовать переформулировку вопросов (query rewriting) для повышения качества поиска."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
